include "cluster.conf"

streamanalyzer {

  app-name = "StreamAnalyzer"

  kafka {
    brokers = "kafka-1:9092,kafka-2:9092,kafka-3:9092"
    brokers = ${?KAFKA_BROKERS}

    group.id = "weather.group"
    put.topic = "weather.abnormal"
    get.topics = "weather.rawdata" #comma separated topics
  }

  data-format {
    id.ordinal = 0
    temperature.ordinal = 5
    pressure.ordinal = 7
    precip-1h.oridinal = 12

    temperature.metric.threshold = 0.3
  }

  spark {
    mbatch.ingest_rate.max = 5000 # max # of messages per second for each partition
    mbatch.duration = 2000 # unit in ms
    mbatch.window = 3
    mbatch.slide = 1

    checkpoint.interval = 10
    checkpoint.dir="/home/winston/draft/spark/checkpoint" # TODO: replace it with cluster shared storage
  }

  cassandra {
    connection.hosts = "spark-1,spark-2"
    connection.hosts = ${?CASSANDRA_HOSTS}
    connection.keepalive = 1000 #unit in ms, add "spark.mbatch.duration" as final timeout value

    keyspace = "isd_weather_data"
    table.raw = "raw_weather_data"
    table.aggreg-temperature = "monthly_aggregate_temperature"
    table.moving-avg-temperature = "moving_average_temperature"
  }

}
